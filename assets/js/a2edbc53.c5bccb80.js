"use strict";(self.webpackChunkgit_ops_doc=self.webpackChunkgit_ops_doc||[]).push([[442],{3905:(e,t,r)=>{r.d(t,{Zo:()=>u,kt:()=>m});var n=r(7294);function a(e,t,r){return t in e?Object.defineProperty(e,t,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[t]=r,e}function o(e,t){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),r.push.apply(r,n)}return r}function i(e){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{};t%2?o(Object(r),!0).forEach((function(t){a(e,t,r[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(r,t))}))}return e}function l(e,t){if(null==e)return{};var r,n,a=function(e,t){if(null==e)return{};var r,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||(a[r]=e[r]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)r=o[n],t.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(a[r]=e[r])}return a}var s=n.createContext({}),c=function(e){var t=n.useContext(s),r=t;return e&&(r="function"==typeof e?e(t):i(i({},t),e)),r},u=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var r=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),p=c(r),h=a,m=p["".concat(s,".").concat(h)]||p[h]||d[h]||o;return r?n.createElement(m,i(i({ref:t},u),{},{components:r})):n.createElement(m,i({ref:t},u))}));function m(e,t){var r=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=r.length,i=new Array(o);i[0]=h;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[p]="string"==typeof e?e:a,i[1]=l;for(var c=2;c<o;c++)i[c]=r[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,r)}h.displayName="MDXCreateElement"},4061:(e,t,r)=>{r.r(t),r.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var n=r(7462),a=(r(7294),r(3905));const o={},i="Monitoring",l={unversionedId:"Archi/Monitoring",id:"Archi/Monitoring",title:"Monitoring",description:"Having a cluster is great, but it's not enough. We need to monitor it. For that, we use what's called an extended PromStack.",source:"@site/docs/Archi/Monitoring.md",sourceDirName:"Archi",slug:"/Archi/Monitoring",permalink:"/WeeboGitOps/docs/Archi/Monitoring",draft:!1,editUrl:"https://github.com/batleforc/WeeboGitOps/tree/Doc/Main/docs/Archi/Monitoring.md",tags:[],version:"current",frontMatter:{},sidebar:"intro",previous:{title:"CI / CD",permalink:"/WeeboGitOps/docs/Archi/CiCD"},next:{title:"Node",permalink:"/WeeboGitOps/docs/Archi/Node"}},s={},c=[{value:"Grafana",id:"grafana",level:2},{value:"Prometheus",id:"prometheus",level:2},{value:"Loki",id:"loki",level:2},{value:"Tempo",id:"tempo",level:2},{value:"AlertManager",id:"alertmanager",level:2}],u={toc:c},p="wrapper";function d(e){let{components:t,...o}=e;return(0,a.kt)(p,(0,n.Z)({},u,o,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"monitoring"},"Monitoring"),(0,a.kt)("p",null,"Having a cluster is great, but it's not enough. We need to monitor it. For that, we use what's called an extended PromStack."),(0,a.kt)("p",null,"Monitoring is a very important part of a cluster. It allows us to know the current state of our cluster and to be alerted when something goes wrong. And if things go wrong, we can use the logs and traces to find the root cause of the problem."),(0,a.kt)("mermaid",{value:"flowchart TB;\n  subgraph Monitoring;\n    subgraph Dashboard;\n      Grafana\n    end\n    subgraph Alerting;\n      AlertManager\n    end\n    subgraph Log;\n      Loki\n      Promtail\n    end\n    subgraph Metric\n      Prometheus\n    end\n    subgraph Tracing\n      Tempo\n    end\n  end\n\n  Grafana ===>|Query PromQL| Prometheus\n  Grafana ===>|Query LogQL| Loki\n  Grafana ===>|Query TraceQL| Tempo\n  Promtail --\x3e|Send logs from container| Loki\n  AlertManager --\x3e|Querry then trigger alerts| Prometheus"}),(0,a.kt)("h2",{id:"grafana"},"Grafana"),(0,a.kt)("p",null,'Grafana is a dashboarding tool that can display data from multiple "datasources". In our case, we use Prometheus to collect, querry and store metrics, Loki for logs and Tempo for traces.'),(0,a.kt)("p",null,"If you are collecting the right data, you can create some nice dashboard like this one that allow me to know the current state of my cluster:"),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Grafana Dashboard",src:r(4309).Z,width:"947",height:"594"})),(0,a.kt)("h2",{id:"prometheus"},"Prometheus"),(0,a.kt)("p",null,"Prometheus is a monitoring tool that collect metrics from multiple sources. It can also querry the data it collected and store it. It's the main datasource of Grafana."),(0,a.kt)("p",null,'With the help of grafana and PromQL, we can for exemple querry every metrics collected in the "monitoring" namespace and display them in a graph:'),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Prometheus Querry",src:r(3193).Z,width:"950",height:"957"})),(0,a.kt)("p",null,"Here without formating, it doesn't make sense because there is too much different data."),(0,a.kt)("h2",{id:"loki"},"Loki"),(0,a.kt)("p",null,"Loki is a service that allow to store and explore logs. It's the main datasource of Grafana for logs."),(0,a.kt)("p",null,'With the help of grafana and LogQL, we can for exemple querry every logs collected in the "monitoring" namespace and display them in a table:'),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Loki Querry",src:r(8885).Z,width:"955",height:"957"})),(0,a.kt)("p",null,"Here without formating, it doesn't make sense because there is too much different log."),(0,a.kt)("h2",{id:"tempo"},"Tempo"),(0,a.kt)("p",null,"Tempo is a service that allow to store and explore traces. It's the main datasource of Grafana for traces. Tempo is able to store traces from multiple sources like Jaeger or OpenTelemetry."),(0,a.kt)("p",null,"With the help of grafana and TraceQL, we can for exemple querry every traces collected:"),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Tempo Querry",src:r(7283).Z,width:"1105",height:"962"})),(0,a.kt)("p",null,"At the moment not much traces are collected, but it's a good start."),(0,a.kt)("h2",{id:"alertmanager"},"AlertManager"),(0,a.kt)("p",null,"AlertManager is a service that allow to trigger alerts based on querry. It's the main datasource of Grafana for alerts. It's included in the Grafana ui."),(0,a.kt)("p",null,"Once it has been configured, it can send alerts to multiple channels like email, slack, discord, etc."),(0,a.kt)("p",null,"With the the help of grafana and the different querry language, we can follow the state of our alerts:"),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Alertmanager",src:r(6662).Z,width:"919",height:"583"})))}d.isMDXComponent=!0},4309:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/dashboard-k3s-efa130ccf29ad42085f6adc62475c2b4.png"},6662:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/explore-alert-b8cf838c69cdd9920104dd1b6b9d8e84.png"},8885:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/explore-loki-b2a621594e9bac6a0f1a957f7fd994f2.png"},3193:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/explore-prom-monitoring-4e21e80833063274f9c07f0cd8612d1b.png"},7283:(e,t,r)=>{r.d(t,{Z:()=>n});const n=r.p+"assets/images/explore-tempo-8569ccca5295bcb8f6b89ac2a3b167b2.png"}}]);